{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FVSAc9zRy3L9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/mail_data.csv\"\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "zJ91EqBqy861"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "# Assuming the dataset has 'label' (spam/ham) and 'text' columns\n",
        "label_encoder = LabelEncoder()\n",
        "data['Category'] = label_encoder.fit_transform(data['Category'])"
      ],
      "metadata": {
        "id": "ejG8HjEgy83U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['Message']\n",
        "y = data['Category']"
      ],
      "metadata": {
        "id": "xEXc3x6ey80o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "wryQ8ffXy8yF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "pTHQhgtDy8vl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_padded = pad_sequences(X_train_seq, maxlen=100)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=100)"
      ],
      "metadata": {
        "id": "_C2b_0bfy8s0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build RNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=128, input_length=100),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUsB_58Ay8qL",
        "outputId": "975b9579-0bfc-4a0e-da3e-dd0d91444280"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0wf2_Xuky8nR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQA1007Ny8kg",
        "outputId": "153886eb-c527-46fa-d2a9-450c1ef0d485"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 129ms/step - accuracy: 0.8811 - loss: 0.3114 - val_accuracy: 0.9776 - val_loss: 0.0837\n",
            "Epoch 2/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.9895 - loss: 0.0407 - val_accuracy: 0.9821 - val_loss: 0.0715\n",
            "Epoch 3/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.9955 - loss: 0.0182 - val_accuracy: 0.9821 - val_loss: 0.0811\n",
            "Epoch 4/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 120ms/step - accuracy: 0.9986 - loss: 0.0079 - val_accuracy: 0.9832 - val_loss: 0.0794\n",
            "Epoch 5/5\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 124ms/step - accuracy: 0.9998 - loss: 0.0023 - val_accuracy: 0.9832 - val_loss: 0.0834\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c9f8f084f10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7E67nR7y8hZ",
        "outputId": "307e7195-d3db-4aad-ea00-89e00ef410d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9871 - loss: 0.0633\n",
            "Test Accuracy: 0.9883407950401306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test, verbose=0)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykxhJPfNzjPI",
        "outputId": "9664e3ac-0652-4e50-c2fe-7451881a57f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.058238185942173004\n",
            "Test Accuracy: 0.9883407950401306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "y_pred_probs = model.predict(X_test_padded)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr5iqMy_zjJU",
        "outputId": "96b7296e-964b-4520-820f-0ff9e7a39c60"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "IqT1TJxCzjEL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKUtLhZvzi87",
        "outputId": "28a5b014-e0ea-4080-a722-3f25563e821c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9857142857142858\n",
            "Recall: 0.9261744966442953\n",
            "F1 Score: 0.9550173010380623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report for a detailed breakdown\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Ham', 'Spam']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozviZkpZ1cEN",
        "outputId": "5f2021cc-81b8-4b16-c30f-57a613594f77"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Ham       0.99      1.00      0.99       966\n",
            "        Spam       0.99      0.93      0.96       149\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.99      0.96      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess and predict user input\n",
        "def predict_email(email_text):\n",
        "    # Tokenize and pad the input email text\n",
        "    email_seq = tokenizer.texts_to_sequences([email_text])\n",
        "    email_padded = pad_sequences(email_seq, maxlen=100)\n",
        "\n",
        "    # Predict using the trained model\n",
        "    prediction = model.predict(email_padded)\n",
        "    return \"Spam\" if prediction > 0.5 else \"Ham\"\n",
        "\n",
        "# Take user input\n",
        "print(\"\\n=== Email Spam Detection ===\")\n",
        "while True:\n",
        "    user_input = input(\"Enter an email to classify (or type 'exit' to quit): \").strip()\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    result = predict_email(user_input)\n",
        "    print(f\"Prediction: {result}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUsp7rBI1b9Y",
        "outputId": "d424baba-216e-4352-ba2c-f7c2995b1f4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Email Spam Detection ===\n",
            "Enter an email to classify (or type 'exit' to quit): Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Prediction: Ham\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): Upgrade to our premium plan for exclusive access to premium content and features.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Prediction: Spam\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): You're a winner! Click here to claim your exclusive prize.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Prediction: Spam\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): Thank you for your feedback. We're always striving to improve our services.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Prediction: Ham\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): We're sorry for the inconvenience. Our website will be back online shortly.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Prediction: Ham\n",
            "\n",
            "Enter an email to classify (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    }
  ]
}